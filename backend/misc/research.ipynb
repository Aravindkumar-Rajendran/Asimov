{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textacy\n",
      "  Downloading textacy-0.12.0-py3-none-any.whl (208 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.4/208.4 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting catalogue~=2.0\n",
      "  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting spacy>=3.0.0\n",
      "  Downloading spacy-3.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cytoolz>=0.10.1\n",
      "  Downloading cytoolz-0.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx>=2.0\n",
      "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyphen>=0.10.0\n",
      "  Downloading pyphen-0.13.2-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cachetools>=4.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting jellyfish>=0.8.0\n",
      "  Downloading jellyfish-0.9.0.tar.gz (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.10.0 in /mnt/Work/My_works/AI_projects/Asimov/venv/lib/python3.10/site-packages (from textacy) (2.28.1)\n",
      "Collecting scikit-learn>=0.19.0\n",
      "  Downloading scikit_learn-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /mnt/Work/My_works/AI_projects/Asimov/venv/lib/python3.10/site-packages (from textacy) (1.23.5)\n",
      "Collecting scipy>=0.17.0\n",
      "  Using cached scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n",
      "Requirement already satisfied: tqdm>=4.19.6 in /mnt/Work/My_works/AI_projects/Asimov/venv/lib/python3.10/site-packages (from textacy) (4.64.1)\n",
      "Collecting joblib>=0.13.0\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting toolz>=0.8.0\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /mnt/Work/My_works/AI_projects/Asimov/venv/lib/python3.10/site-packages (from requests>=2.10.0->textacy) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /mnt/Work/My_works/AI_projects/Asimov/venv/lib/python3.10/site-packages (from requests>=2.10.0->textacy) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/Work/My_works/AI_projects/Asimov/venv/lib/python3.10/site-packages (from requests>=2.10.0->textacy) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/Work/My_works/AI_projects/Asimov/venv/lib/python3.10/site-packages (from requests>=2.10.0->textacy) (3.4)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/Work/My_works/AI_projects/Asimov/venv/lib/python3.10/site-packages (from spacy>=3.0.0->textacy) (22.0)\n",
      "Collecting wasabi<1.1.0,>=0.9.1\n",
      "  Using cached wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.10\n",
      "  Using cached spacy_legacy-3.0.10-py2.py3-none-any.whl (21 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 KB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typer<0.8.0,>=0.3.0\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: setuptools in /mnt/Work/My_works/AI_projects/Asimov/venv/lib/python3.10/site-packages (from spacy>=3.0.0->textacy) (59.6.0)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: jinja2 in /mnt/Work/My_works/AI_projects/Asimov/venv/lib/python3.10/site-packages (from spacy>=3.0.0->textacy) (3.1.2)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Downloading thinc-8.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (806 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.5/806.5 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (491 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /mnt/Work/My_works/AI_projects/Asimov/venv/lib/python3.10/site-packages (from spacy>=3.0.0->textacy) (1.10.2)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Downloading smart_open-6.2.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.1.0 in /mnt/Work/My_works/AI_projects/Asimov/venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy>=3.0.0->textacy) (4.4.0)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.0.3-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /mnt/Work/My_works/AI_projects/Asimov/venv/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy>=3.0.0->textacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/Work/My_works/AI_projects/Asimov/venv/lib/python3.10/site-packages (from jinja2->spacy>=3.0.0->textacy) (2.1.1)\n",
      "Using legacy 'setup.py install' for jellyfish, since package 'wheel' is not installed.\n",
      "Installing collected packages: wasabi, cymem, typer, toolz, threadpoolctl, spacy-loggers, spacy-legacy, smart-open, scipy, pyphen, networkx, murmurhash, langcodes, joblib, jellyfish, catalogue, cachetools, blis, srsly, scikit-learn, preshed, pathy, cytoolz, confection, thinc, spacy, textacy\n",
      "  Running setup.py install for jellyfish ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed blis-0.7.9 cachetools-5.2.0 catalogue-2.0.8 confection-0.0.3 cymem-2.0.7 cytoolz-0.12.0 jellyfish-0.9.0 joblib-1.2.0 langcodes-3.3.0 murmurhash-1.0.9 networkx-2.8.8 pathy-0.10.1 preshed-3.0.8 pyphen-0.13.2 scikit-learn-1.2.0 scipy-1.9.3 smart-open-6.2.0 spacy-3.4.3 spacy-legacy-3.0.10 spacy-loggers-1.0.4 srsly-2.4.5 textacy-0.12.0 thinc-8.1.5 threadpoolctl-3.1.0 toolz-0.12.0 typer-0.7.0 wasabi-0.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy\n",
    "about_talk_text = ('The talk will introduce reader about Use'\n",
    "                    ' cases of Natural Language Processing in' \n",
    "                                      ' Fintech')\n",
    "pattern = r'<VERB>?<ADV>*<VERB>+'\n",
    "about_talk_doc = textacy.make_spacy_doc(about_talk_text,\n",
    "                                         lang='en_core_web_sm')\n",
    "verb_phrases = textacy.extract.matches.regex_matches(about_talk_doc, pattern)\n",
    "# Print all Verb Phrase\n",
    "for chunk in verb_phrases:\n",
    "    print(chunk)\n",
    "\n",
    "\n",
    "# for chunk in about_talk_doc.noun_chunks:\n",
    "#     print (chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy   \n",
    "from spacy.matcher import Matcher\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm') \n",
    "\n",
    "sentence = 'The author was staring pensively as she wrote.'\n",
    "pattern = [{'POS': 'VERB', 'OP': '?'},\n",
    "           {'POS': 'ADV', 'OP': '*'},\n",
    "           {'POS': 'AUX', 'OP': '*'},\n",
    "           {'POS': 'VERB', 'OP': '+'}]\n",
    "\n",
    "# instantiate a Matcher instance\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"Verb phrase\", [pattern])\n",
    "\n",
    "doc = nlp(sentence) \n",
    "# call the matcher to find matches \n",
    "matches = matcher(doc)\n",
    "spans = [doc[start:end] for _, start, end in matches]\n",
    "\n",
    "fil_spans = filter_spans(spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil_spans[0].end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The author *was staring* pensively as she wrote.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[:fil_spans[0].start].text + \" *\" + fil_spans[0].text + \"* \" + doc[fil_spans[0].end: ].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'was staring'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil_spans[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author\n",
      "she\n"
     ]
    }
   ],
   "source": [
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[-1].is_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doc[-1].is_punct: idx = -2\n",
    "else: idx = -1\n",
    "\n",
    "hint = doc[idx].text\n",
    "dashes = len(hint.split())\n",
    "text = doc[:idx].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The author was staring pensively as she'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3840da848cb92b0c399f1f5f4392b461f2f9ce0473cd70b9b8970d27786da197"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
